1
00:00:01,000 --> 00:00:05,500
[1차수: RAG란 무엇인가?] 안녕하세요! AI가 우리 회사의 내부 문서까지 학습한 듯 답변하게 만드는 RAG 기술 과정입니다.

2
00:00:06,000 --> 00:00:11,000
최신 정보 반영이 어렵고 환각 현상이 있는 LLM의 한계를 외부 데이터 검색으로 해결하는 원리를 이해해 봅니다.

3
00:03:01,000 --> 00:03:05,500
[2차수: 텍스트 임베딩의 이해] 컴퓨터가 문장의 의미를 어떻게 숫자로 이해할까요? 임베딩 벡터의 개념을 배웁니다.

4
00:03:06,000 --> 00:03:11,000
단어와 문장을 다차원 공간에 배치하여 의미적 유사도를 계산하는 핵심 기술을 실습합니다.

5
00:06:01,000 --> 00:06:05,500
[3차수: 벡터 데이터베이스(Vector DB) 선택] 방대한 벡터 데이터를 빠르게 검색하기 위한 전용 DB를 알아봅니다.

6
00:06:06,000 --> 00:06:11,000
Pinecone, Chroma, Milvus 등 주요 벡터 DB의 특징을 비교하고 우리 환경에 맞는 툴을 선정합니다.

7
00:09:01,000 --> 00:09:05,500
[4차수: 문서 전처리와 청킹(Chunking)] 긴 PDF나 워드 문서를 AI가 읽기 좋게 적절한 크기로 자르는 기술입니다.

8
00:09:06,000 --> 00:09:11,000
문맥이 끊기지 않게 텍스트를 분할하고 메타데이터를 부여하여 검색 정확도를 높이는 노하우를 공유합니다.

9
00:12:01,000 --> 00:12:05,500
[5차수: 검색 성능 최적화(Retrieval)] 수천 개의 문서 중 질문과 가장 관련 있는 조각을 찾아내는 단계입니다.

10
00:12:06,000 --> 00:12:11,000
키워드 검색과 의미 검색을 결합한 하이브리드 검색 기법을 통해 검색 품질을 극대화해 봅니다.

11
00:15:01,000 --> 00:15:05,500
[6차수: 프롬프트 엔지니어링과 RAG] 검색된 정보를 바탕으로 AI가 답변을 생성하도록 지무를 내리는 법을 배웁니다.

12
00:15:06,000 --> 00:15:11,000
"주어진 참고 자료에 근거해서만 답변해라"와 같은 제약 조건을 통해 신뢰도 높은 답변을 유도합니다.

13
00:18:01,000 --> 00:18:05,500
[7차수: 오픈소스 LLM 활용하기] 보안이 중요한 기업을 위해 사내 서버에 설치하는 Llama 3 등의 로컬 모델을 다룹니다.

14
00:18:06,000 --> 00:18:11,000
외부 API 호출 없이 폐쇄망 환경에서 작동하는 독립적인 AI 시스템 구축 전략을 수립합니다.

15
00:21:01,000 --> 00:21:05,500
[8차수: 대화형 UI와 챗봇 연동] 구축된 RAG 엔진을 직원들이 편리하게 쓸 수 있도록 웹 인터페이스를 입힙니다.

16
00:21:06,000 --> 00:21:11,000
Streamlit이나 Gradio를 활용해 코딩 몇 줄로 전문가 수준의 AI 챗봇 화면을 구현해 봅니다.

17
00:24:01,000 --> 00:24:05,500
[9차수: RAG 시스템 성능 평가] 우리 AI가 얼마나 정확하게 답변할까요? 정량적인 평가 지표를 도입합니다.

18
00:24:06,000 --> 00:24:11,000
검색 정확도와 답변의 충실도를 측정하고, 사용자의 피드백을 반영해 시스템을 고도화하는 과정을 학습합니다.

19
00:27:01,000 --> 00:27:05,500
[10차수: 사내 지식 자산의 AI화 완성] 이제 회사의 모든 규정, 매뉴얼, 보고서가 AI의 지식이 되었습니다.

20
00:27:06,000 --> 00:27:11,000
지식 전수 시간을 단축하고 업무 몰입도를 높이는 성공적인 RAG 도입 사례를 정리하며 마무리합니다.