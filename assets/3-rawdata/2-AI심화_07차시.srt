1
00:00:01,000 --> 00:00:05,500
[1차수: 왜 AI 거버넌스인가?] 안녕하세요. AI 도입만큼 중요한 기술적, 윤리적 안전판을 구축하는 과정입니다.

2
00:00:06,000 --> 00:00:11,000
기업 경쟁력을 높이는 AI가 때로는 리스크가 될 수 있습니다. 안전한 활용을 위한 거버넌스의 정의를 알아봅니다.

3
00:03:01,000 --> 00:03:05,500
[2차수: 생성형 AI와 저작권 분쟁] AI가 생성한 결과물의 주인은 누구일까요? 현재 진행 중인 저작권 논의를 살펴봅니다.

4
00:03:06,000 --> 00:03:11,000
학습 데이터의 권리 관계와 생성물 활용 시 발생할 수 있는 법적 리스크를 최소화하는 법을 배웁니다.

5
00:06:01,000 --> 00:06:05,500
[3차수: 기업 내부 데이터 유출 방지] 챗GPT에 회사 기밀을 입력해도 될까요? 데이터 프라이버시의 핵심을 다룹니다.

6
00:06:06,000 --> 00:06:11,000
입력값 차단 도구와 API 활용 시의 데이터 학습 제외 설정 등 기술적 방어 체계를 실습합니다.

7
00:09:01,000 --> 00:09:05,500
[4차수: 환각 현상(Hallucination) 관리] AI가 그럴듯한 거짓말을 하는 이유와 이를 검증하는 프로세스를 설계합니다.

8
00:09:06,000 --> 00:11,000
RAG(검색 증강 생성) 기술이 어떻게 AI의 답변 정확도를 높이고 신뢰성을 확보하는지 이해해 봅니다.

9
00:12:01,000 --> 00:12:05,500
[5차수: 알고리즘의 편향성과 공정성] AI가 특정 집단에 차별적인 결과를 내놓지 않도록 데이터의 편향성을 점검합니다.

10
00:12:06,000 --> 00:12:11,000
공정한 AI 모델을 만들기 위해 개발 및 운영 단계에서 확인해야 할 체크리스트를 공유합니다.

11
00:15:01,000 --> 00:15:05,500
[6차수: AI 활용 가이드라인 수립] 사내 구성원들이 지켜야 할 'AI 사용 헌장'을 직접 작성해 보는 시간입니다.

12
00:15:06,000 --> 00:15:11,000
허용되는 도구의 범위와 금지된 데이터 유형을 명확히 정의하여 혼선을 방지하는 법을 배웁니다.

13
00:18:01,000 --> 00:18:05,500
[7차수: 프롬프트 인젝션과 보안 공격] AI 모델을 속여 기밀을 빼내는 새로운 공격 방식인 프롬프트 인젝션을 알아봅니다.

14
00:18:06,000 --> 00:18:11,000
이러한 공격으로부터 시스템을 보호하기 위한 필터링 및 샌드박스 보안 전략을 구축합니다.

15
00:21:01,000 --> 00:21:05,500
[8차수: AI 투명성과 설명 가능성] AI가 왜 이런 결론을 내렸는지 설명할 수 있어야 합니다(XAI).

16
00:21:06,000 --> 00:21:11,000
의사결정 과정의 투명성을 확보하여 사용자의 신뢰를 얻는 기술적 도구들을 살펴봅니다.

17
00:24:01,000 --> 00:24:05,500
[9차수: 글로벌 AI 규제 동향] EU AI Act 등 세계 각국에서 도입 중인 AI 관련 법안과 규제를 분석합니다.

18
00:24:06,000 --> 00:24:11,000
글로벌 시장 진출 시 반드시 고려해야 할 규제 준수(Compliance) 요건들을 정리합니다.

19
00:27:01,000 --> 00:27:05,500
[10차수: 지속 가능한 AI 경영] 이제 보안과 윤리는 선택이 아닌 필수입니다. 전 과정을 요약하며 마무리합니다.

20
00:27:06,000 --> 00:27:11,000
책임감 있는 AI 활용을 통해 기업의 가치를 높이는 리더로 거듭나시길 바랍니다.