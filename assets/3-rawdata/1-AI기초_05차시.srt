1
00:00:01,000 --> 00:00:05,500
[1차수: 게임하듯 배우는 AI] 안녕하세요! 5강에서는 아주 특별한 학습법, 강화학습을 다룹니다.

2
00:00:06,000 --> 00:00:11,000
정답지를 보는 대신, 직접 부딪히며 경험을 통해 스스로 최선의 방법을 찾아내는 원리를 알아봅시다.

3
00:03:01,000 --> 00:03:05,500
[2차수: 보상과 패널티의 마법] 강화학습의 핵심은 '당근과 채찍'입니다. 잘하면 보상을, 못하면 벌점을 주죠.

4
00:03:06,000 --> 00:03:11,000
기계는 더 많은 보상을 얻기 위해 자신의 행동을 스스로 수정해 나갑니다. 강아지 훈련과 아주 비슷하죠.

5
00:06:01,000 --> 00:06:05,500
[3차수: 에이전트와 환경] 주인공인 '에이전트'가 놓여진 '환경' 안에서 상호작용하는 구조를 이해합니다.

6
00:06:06,000 --> 00:06:11,000
마치 게임 캐릭터가 맵 안에서 아이템을 먹고 적을 피하며 점수를 쌓는 것과 같은 이치입니다.

7
00:09:01,000 --> 00:09:05,500
[4차수: 상태(State)와 행동(Action)] 에이전트는 현재 상황을 파악하고, 그에 맞는 행동을 선택합니다.

8
00:09:06,000 --> 00:11,000
벽 앞에 서 있는 상태라면 '점프'나 '회전' 같은 행동을 결정해야 하죠. 매 순간의 선택이 결과를 바꿉니다.

9
00:12:01,000 --> 00:12:05,500
[5차수: 탐험 vs 이용의 딜레마] 아는 길로만 갈 것인가, 아니면 새로운 길을 개척해 볼 것인가?

10
00:12:06,000 --> 00:12:11,000
더 큰 보상을 찾기 위해 가보지 않은 길을 시도하는 '탐험'의 중요성을 인공지능 관점에서 살펴봅니다.

11
00:15:01,000 --> 00:15:05,500
[6차수: 알파고와 강화학습] 전 세계를 놀라게 한 알파고 역시 강화학습을 통해 무수히 많은 대국을 치렀습니다.

12
00:15:06,000 --> 00:15:11,000
스스로와 대결하며 승리라는 보상을 얻기 위해 최적의 수를 찾아냈던 과정을 복기해 봅시다.

13
00:18:01,000 --> 00:18:05,500
[7차수: 자율주행과 강화학습] 도로 위에서 사고를 피하고 목적지에 도달하는 것도 강화학습의 영역입니다.

14
00:18:06,000 --> 00:18:11,000
다양한 돌발 상황 속에서 안전 주행이라는 높은 보상을 얻기 위해 운전 지능을 고도화하는 사례를 다룹니다.

15
00:21:01,000 --> 00:21:05,500
[8차수: 강화학습의 한계와 도전] 하지만 현실 세계는 게임처럼 쉽지 않습니다. 보상이 너무 늦게 오기도 하죠.

16
00:21:06,000 --> 00:21:11,000
복잡한 환경에서 보상을 제대로 정의하는 것이 얼마나 어려운지, 기술적 난제들을 함께 고민해 봅니다.

17
00:24:01,000 --> 00:24:05,500
[9차수: 비즈니스에 적용하는 강화학습] 마케팅이나 재고 관리에도 강화학습을 쓸 수 있을까요?

18
00:24:06,000 --> 00:24:11,000
고객 만족도나 수익 극대화라는 보상을 설정하고 전략을 최적화하는 비즈니스 활용 방안을 제안합니다.

19
00:27:01,000 --> 00:27:05,500
[10차수: 강화학습 총정리] 지도, 비지도에 이어 강화학습까지, 머신러닝의 3대 학습법을 모두 마스터하셨습니다.

20
00:27:06,000 --> 00:27:11,000
이제 다음 시간에는 이 모든 학습을 가능하게 하는 기계의 뇌, '인공신경망'의 구조로 깊이 들어가 보겠습니다.