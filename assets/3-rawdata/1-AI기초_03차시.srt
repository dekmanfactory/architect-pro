1
00:00:01,000 --> 00:00:05,500
[1차수: 기계가 배운다는 것의 의미] 안녕하세요! 3강에서는 '머신러닝'의 진짜 의미를 파헤쳐 봅니다.

2
00:00:06,000 --> 00:00:11,000
사람이 규칙을 일일이 정해주는 대신, 기계가 스스로 데이터에서 규칙을 찾는 과정이 바로 학습입니다.

3
00:03:01,000 --> 00:03:05,500
[2차수: 전통적 프로그래밍 vs 머신러닝] 예전에는 사람이 '스팸 메일'의 특징을 정의했다면, 이제는 아닙니다.

4
00:03:06,000 --> 00:03:11,000
수천 통의 메일을 기계에게 던져주고, 기계가 스스로 스팸의 패턴을 발견하게 만드는 차이를 이해해 봅니다.

5
00:06:01,000 --> 00:06:05,500
[3차수: 머신러닝의 3대 요소] 머신러닝을 위해서는 데이터, 모델, 그리고 평가라는 세 가지 기둥이 필요합니다.

6
00:06:06,000 --> 00:06:11,000
이 세 가지 요소가 어떻게 톱니바퀴처럼 맞물려 돌아가며 결과물을 내놓는지 전체 지도를 그려봅시다.

7
00:09:01,000 --> 00:09:05,500
[4차수: 특성(Feature)과 라벨(Label)] 데이터에도 이름이 있습니다. 예측하고 싶은 '정답'은 라벨입니다.

8
00:09:06,000 --> 00:11,000
정답을 맞히기 위해 참고하는 힌트들을 '특성'이라고 부르는데, 좋은 힌트를 찾는 것이 실력의 핵심이죠.

9
00:12:01,000 --> 00:12:05,500
[5차수: 훈련 데이터와 테스트 데이터] 공부한 문제만 잘 풀면 안 되겠죠? 기계도 예습용과 시험용 데이터를 나눕니다.

10
00:12:06,000 --> 00:12:11,000
학습하지 않은 새로운 데이터에서도 실력을 발휘할 수 있는지 확인하는 과정의 중요성을 배웁니다.

11
00:15:01,000 --> 00:15:05,500
[6차수: 모델의 가중치(Weight) 이해하기] 기계의 뇌 안에서는 수많은 '중요도 점수'가 조정되고 있습니다.

12
00:15:06,000 --> 00:15:11,000
어떤 힌트가 정답에 큰 영향을 미치는지 가중치를 미세하게 조정하며 정답에 가까워지는 원리를 다룹니다.

13
00:18:01,000 --> 00:18:05,500
[7차수: 손실(Loss)을 줄여라!] 기계의 목표는 단순합니다. '틀린 정도'를 최소화하는 것이죠.

14
00:18:06,000 --> 00:18:11,000
정답과 예측값의 차이를 숫자로 계산하고, 이 숫자를 줄이기 위해 고군분투하는 모델의 노력을 알아봅니다.

15
00:21:01,000 --> 00:21:05,500
[8차수: 회귀 vs 분류, 무엇이 다른가?] 내일의 주가를 맞히는 것과 개인지 고양이인지를 맞히는 것은 다릅니다.

16
00:21:06,000 --> 00:21:11,000
연속적인 숫자를 맞히는 '회귀'와 유형을 구분하는 '분류'의 기본 개념을 명확히 정리합니다.

17
00:24:01,000 --> 00:24:05,500
[9차수: 과적합(Overfitting)의 덫] 너무 공부를 많이 해도 병이 됩니다. 암기만 잘하는 바보가 될 수 있거든요.

18
00:24:06,000 --> 00:24:11,000
학습 데이터에는 100점이지만 실전에서는 0점인 모델을 방지하기 위한 유연한 학습의 기술을 소개합니다.

19
00:27:01,000 --> 00:27:05,500
[10차수: 머신러닝 원리 요약] 이제 기계가 어떻게 똑똑해지는지 그 기초적인 메커니즘을 이해하셨습니다.

20
00:27:06,000 --> 00:27:11,000
다음 시간에는 기계가 학습하는 구체적인 세 가지 스타일, '지도/비지도/강화학습'을 본격 비교해 봅니다.