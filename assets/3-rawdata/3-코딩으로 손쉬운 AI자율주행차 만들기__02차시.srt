1
00:00:01,000 --> 00:00:05,000
[2차수: 자율주행의 눈, 센서 이해하기] 안녕하세요! 지난 시간 시스템 구조에 이어, 오늘은 하드웨어를 살펴봅니다.

2
00:00:05,500 --> 00:00:10,000
자율주행차가 주변 상황을 인지하려면 인간의 눈과 귀 역할을 하는 다양한 센서가 조화를 이뤄야 합니다.

3
00:00:10,500 --> 00:00:15,500
가장 먼저 '카메라'입니다. 도로의 차선, 표지판, 신호등의 색상을 구분하는 데 가장 핵심적인 역할을 하죠.

4
00:03:00,000 --> 00:03:05,000
하지만 카메라는 빛이 없는 밤이나 악천후에는 한계가 있습니다. 이때 필요한 것이 '라이다(LiDAR)'와 '레이더'입니다.

5
00:03:05,500 --> 00:03:10,500
라이다는 레이저를 쏘아 반사되는 시간으로 거리를 측정해, 주변을 정밀한 3D 지도로 그려냅니다.

6
00:06:00,000 --> 00:06:05,000
레이더는 전파를 이용해 물체의 거리와 속도를 측정하며, 안개나 비가 오는 상황에서도 매우 안정적입니다.

7
00:09:00,000 --> 00:09:14,000
우리는 이번 실습에서 고가의 장비 대신, 소형 임베디드 보드와 호환되는 카메라 모듈을 주로 사용할 것입니다.

8
00:12:00,000 --> 00:12:05,500
다음은 차의 두뇌 역할을 하는 '컴퓨팅 유닛'입니다. 라즈베리 파이나 젯슨 나노 같은 보드가 쓰이죠.

9
00:12:06,000 --> 00:12:11,000
이 작은 보드 위에서 우리가 짠 파이썬 코드가 실시간으로 센서 데이터를 처리하고 모터를 제어하게 됩니다.

10
00:15:00,000 --> 00:15:05,000
또한 차의 기울기나 방향 전환을 감지하는 IMU(관성 측정 장치) 센서의 역할도 중요합니다.

11
00:18:00,000 --> 00:18:05,500
이런 다양한 센서 데이터를 하나로 합쳐서 판단하는 것을 '센서 퓨전(Sensor Fusion)'이라고 부릅니다.

12
00:21:00,000 --> 00:21:05,000
카메라가 본 정보와 레이더가 측정한 거리를 결합해 더 정확한 판단을 내리는 기술이죠.

13
00:24:00,000 --> 00:24:05,000
실습용 차량 키트를 조립할 때 각 센서의 각도와 위치가 코딩 결과에 어떤 영향을 주는지도 직접 경험해 볼 겁니다.

14
00:27:00,000 --> 00:27:05,000
결국 코딩이란, 이 센서들이 보내오는 '숫자 데이터'를 우리가 원하는 '동작'으로 바꾸는 과정입니다.

15
00:27:05,500 --> 00:27:11,000
2차수 마칩니다. 다음 시간에는 파이썬을 활용해 카메라 영상을 읽어오는 첫 번째 코딩 실습을 시작합니다.