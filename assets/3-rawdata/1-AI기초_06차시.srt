1
00:00:01,000 --> 00:00:05,500
[1차수: 기계의 뇌, 신경망을 만나다] 안녕하세요! 6강에서는 AI의 지능이 만들어지는 집합체, 인공신경망을 배웁니다.

2
00:00:06,000 --> 00:00:11,000
인간의 뇌세포인 뉴런이 서로 신호를 주고받으며 생각하듯, 기계는 어떻게 신호를 처리하는지 알아봅시다.

3
00:03:01,000 --> 00:03:05,500
[2차수: 인공뉴런, 퍼셉트론] 신경망의 가장 작은 단위는 퍼셉트론입니다. 여러 신호를 받아 하나의 결과를 내놓죠.

4
00:03:06,000 --> 00:03:11,000
들어온 정보에 '중요도(가중치)'를 곱해 합산하는 과정이 우리 뇌의 판단 방식과 얼마나 닮았는지 살펴봅니다.

5
00:06:01,000 --> 00:06:05,500
[3차수: 입력층, 은닉층, 출력층] 신경망은 층(Layer)으로 구성됩니다. 정보를 받는 곳과 내보내는 곳이 있죠.

6
00:06:06,000 --> 00:06:11,000
그 사이에 숨겨진 '은닉층'이 바로 AI가 복잡한 생각을 수행하는 핵심 공간임을 이해해 봅니다.

7
00:09:01,000 --> 00:09:05,500
[4차수: 층이 깊어지면 딥러닝이다] 왜 '딥(Deep)' 러닝일까요? 바로 은닉층이 수십, 수백 개로 깊어졌기 때문입니다.

8
00:09:06,000 --> 00:11,000
단순한 판단을 넘어 정교한 추론이 가능해진 딥러닝의 구조적 혁신을 다룹니다.

9
00:12:01,000 --> 00:12:05,500
[5차수: 활성화 함수의 역할] 모든 신호를 다 보낼까요? 아니면 선택적으로 보낼까요? 활성화 함수가 결정합니다.

10
00:12:06,000 --> 00:12:11,000
신경망에 비선형성을 부여하여 복잡한 패턴을 학습할 수 있게 만드는 스위치 역할을 배워봅니다.

11
00:15:01,000 --> 00:15:05,500
[6차수: 연결의 힘, 가중치와 편향] 신경망 학습의 정체는 결국 노드 사이의 연결 강도를 조절하는 것입니다.

12
00:15:06,000 --> 00:15:11,000
수조 개의 연결 고리를 최적화하여 정답을 찾아가는 거대한 네트워크의 힘을 느껴보세요.

13
00:18:01,000 --> 00:18:05,500
[7차수: 순전파(Forward) 이해하기] 데이터가 입력층에서 출력층으로 흘러가며 예측값을 내놓는 과정입니다.

14
00:18:06,000 --> 00:18:11,000
마치 전기가 회로를 따라 흐르듯, 정보가 층을 통과하며 구체화되는 흐름을 시각화해 봅니다.

15
00:21:01,000 --> 00:21:05,500
[8차수: 역전파(Backpropagation) 맛보기] 틀렸다면 고쳐야죠. 오차를 뒤로 보내며 연결 강도를 수정합니다.

16
00:21:06,000 --> 00:21:11,000
딥러닝을 가능하게 한 가장 중요한 알고리즘인 역전파의 기본 원리를 직관적으로 설명합니다.

17
00:24:01,000 --> 00:24:05,500
[9차수: 현대 딥러닝의 눈부신 성과] 이 구조를 바탕으로 사진을 찍고, 말을 하고, 글을 쓰는 AI가 탄생했습니다.

18
00:24:06,000 --> 00:24:11,000
단순한 수학 모델이 어떻게 인간 수준의 인지 능력을 갖추게 되었는지 그 비결을 정리합니다.

19
00:27:01,000 --> 00:27:05,500
[10차수: 인공신경망 구조 요약] 드디어 딥러닝의 하드웨어라 할 수 있는 신경망 구조를 마스터하셨습니다.

20
00:27:06,000 --> 00:27:11,000
다음 시간에는 아무리 좋은 신경망도 이것이 없으면 무용지물인, '데이터'의 세계로 떠나보겠습니다.