1
00:00:01,000 --> 00:00:05,500
[1차수: AI는 항상 중립적일까?] 안녕하세요! 8강에서는 AI의 그림자, '편향성'에 대해 심도 있게 다룹니다.

2
00:00:06,000 --> 00:00:11,000
우리는 흔히 기계가 인간보다 객관적이라 믿지만, AI는 우리가 준 데이터 속의 편견까지 그대로 흡수합니다.

3
00:03:01,000 --> 00:03:05,500
[2차수: 데이터 편향의 실례] 채용 AI가 여성 지원자를 차별하거나, 유색인종을 오인식했던 사례들을 살펴봅니다.

4
00:03:06,000 --> 00:03:11,000
의도치 않게 발생한 기술적 오류가 사회적으로 어떤 파장을 일으킬 수 있는지 확인해 보는 시간입니다.

5
00:06:01,000 --> 00:06:05,500
[3차수: 알고리즘 편향의 메커니즘] 데이터뿐만 아니라 모델을 설계하는 과정에서도 편향은 발생할 수 있습니다.

6
00:06:06,000 --> 00:06:11,000
개발자의 고정관념이나 특정 목적을 위한 가중치 설정이 결과값에 미치는 영향을 분석합니다.

7
00:09:01,000 --> 00:09:05,500
[4차수: 필터 버블(Filter Bubble) 현상] 추천 알고리즘이 우리를 보고 싶은 것만 보게 만드는 현상을 아시나요?

8
00:09:06,000 --> 00:11,000
AI가 만든 정보의 가두리 양식장이 확증 편향을 강화하고 사회적 갈등을 부추기는 원리를 다룹니다.

9
00:12:01,000 --> 00:12:05,500
[5차수: AI 윤리의 5대 원칙] 투명성, 공정성, 안전성, 책임성, 그리고 프라이버시 보호를 배웁니다.

10
00:12:06,000 --> 00:12:11,000
전 세계 기술 기업들이 공통적으로 채택하고 있는 인공지능 윤리 가이드라인의 핵심을 정리합니다.

11
00:15:01,000 --> 00:15:05,500
[6차수: 설명 가능한 AI (XAI)] "왜 이런 결과가 나왔나요?"라는 질문에 AI가 답할 수 있어야 합니다.

12
00:15:06,000 --> 00:15:11,000
결과 도출 과정을 투명하게 공개하여 사용자가 기술을 신뢰하게 만드는 '설명 가능성'의 중요성을 학습합니다.

13
00:18:01,000 --> 00:18:05,500
[7차수: 딥페이크와 가짜 뉴스] 생성형 AI의 발전으로 정교해진 조작 콘텐츠의 위험성을 진단합니다.

14
00:18:06,000 --> 00:18:11,000
진실과 거짓의 경계가 모호해지는 시대에 우리가 가져야 할 비판적 사고와 기술적 대응책을 알아봅니다.

15
00:21:01,000 --> 00:21:05,500
[8차수: AI 레드팀(Red Teaming)] 모델의 취약점과 유해성을 찾기 위해 일부러 공격을 가하는 전문가 집단입니다.

16
00:21:06,000 --> 00:21:11,000
서비스 출시 전, 윤리적 결함을 미리 발견하고 수정하는 방어적 개발 프로세스를 소개합니다.

17
00:24:01,000 --> 00:24:05,500
[9차수: 법적 규제와 글로벌 동향] EU의 AI 법(AI Act) 등 전 세계적인 규제 움직임을 살펴봅니다.

18
00:24:06,000 --> 00:24:11,000
규제가 혁신을 방해하는 걸림돌이 아닌, 안전한 진보를 위한 최소한의 안전장치임을 이해해 봅니다.

19
00:27:01,000 --> 00:27:05,500
[10차수: 인간 중심의 인공지능] 기술의 주인은 결국 인간입니다. 8강의 내용을 총정리합니다.

20
00:27:06,000 --> 00:27:11,000
다음 시간에는 이러한 윤리적 토대 위에 세워질 '미래의 AI 트렌드'에 대해 전망해 보겠습니다.